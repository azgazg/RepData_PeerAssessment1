install.packages("swirl")
library(swirl)
swirl()
library(swirl)
swirl()
install.package("KernSmooth")
install.packages("KernSmooth")
q()
swirl()
library(swirl)
swirl()
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head()
head(plants)
ead(plants,10)
head(plants,10)
tail(plants, 15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6, 4, replace= TRUE)
sample(1:6, 4, replace= TRUE)
sample(1:20, 10)
letters
LETTERS
sample(LETTERS)
flips <- sample(c(0,1), 100, prob(0.3, 0.7))
flips <- sample(c(0,1), 100, prob=(0.3, 0.7))
flips <- sample(c(0,1), 100, prob= c(0.3, 0.7))
flips <- sample(c(0,1), 100, prob= c(0.3, 0.7), replace = TRUE)
flips
sum(flips)
?rbinom
rbinom(1, size=100, prob = 0.7)
flips2 <- rbinom(100, size=1, prob = 0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10, mean = 100, sd = 25)
rpois(5)
rpois(5,4)
rpois(5, 10)
my_pois <- replicate(100, rpois(5, 10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
library(datasets)
data(iris)
?iris
mean(iris[iris$Species == "virginica",]$Sepal.Length)
apply(iris[, 1:4], 2, mean)
library(datasets)
data(mtcars)
?mtcars
with(mtcars, tapply(mpg, cyl, mean))
mean(mtcars[mtcars$cyl == "8",]$hp) - mean(mtcars[mtcars$cyl == "4",]$hp)
debug(ls)
set.seed(1)
rpois(5, 2)
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
exit()
stop
x<- 1
swirl()
library(swirl)
swirl()
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2 <- as.Date("1969-01-01")
unclass(d2)
t1 <- Sys.time()
t
t1
class(t1)
uncalss(t1)
unclass(t1)
t2 <- as.POSIXlt(Sys.time())
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
months(t1)
quarters(t2)
t3 <- "October 17, 1986 08:24"
t4 <- strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time() > t1
Sys.time() - t1
difftime(Sys.time(), t1, units = 'days')
data(cars)
help(cars)
ead(cars)
head(cars)
plot(cars)
help(plot)
plot(x = cars$speed, y = cars$dist)
plot(x = cars$dist, y = cars$speed)
plot(x = cars$dist, y = cars$speed, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping distance")
plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, main = "MyPlot")
plot(cars main = "MyPlot")
plot(cars, main = "MyPlot")
plot(cars, main = "My Plot")
plot(cars, sub = "My Plot Subtitle")
plot(cars, col = 2)
plot(cars, xlim = c(10,15))
plot(cars, pch = 2
)
data(mtcars)
help(boxplot)
boxplot(mpg~cyl, data = mtcars)
hist(mtcars$mpg)
best <- function(state, outcome) {
## Read outcome data
data <- read.csv("~/week4/outcome-of-care-measures.csv", colClasses = "character",na.strings="Not Available")
## Check that state and outcome are valid
validOutcome = c("heart attack","heart failure","pneumonia")
if (!outcome %in% validOutcome) { stop("invalid outcome")}
validState = unique(data[,7])
if (!state %in% validState) stop("invalid state")
## convert outcome name into column name
fullColName <- c("Hospital.30.Day.Death..Mortality..Rates.from.Heart.Attack", "Hospital.30.Day.Death..Mortality..Rates.from.Heart.Failure", "Hospital.30.Day.Death..Mortality..Rates.from.Pneumonia")
colName <- fullColName[match(outcome,validOutcome)]
## Return hospital name in that state with lowest 30-day death rate
data.state <- data[data$State==state,]
idx <- which.min(as.double(data.state[,colName]))
data.state[idx,"Hospital.Name"]
}
# tests
best("TX", "heart attack")
#best("TX", "heart attack")
#best("TX", "heart failure")
#best("MD", "heart attack")
#best("MD", "pneumonia")
#best("BB", "heart attack")
best <- function(state, outcome) {
## Read outcome data
##outcome_name: "heart attack", "heart failure", "pneumonia"
## Check that state and outcome are valid
## Return hospital name in that state with lowest 30-day death
## rate
#read in the desired data
data <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
#check if the state and outcomes are valid
states <- data[ , 7]
outcomes <- c("heart attack", "heart failure", "pneumonia")
if ((state %in% states) == FALSE) {
stop(print("invalid state"))
}
else if ((outcome %in% outcomes) == FALSE) {
stop(print("invalid outcome"))
}
#get the subset of the data with the desired state
new_data <- subset(data, State == state)
#get the desired outcome column from the data file
if (outcome == "heart attack") {
outcome_column <- 11
}
else if (outcome == "heart failure") {
outcome_column <- 17
}
else {
outcome_column <- 23
}
#get rid of the NA's in the desired outcome column
required_columns <- as.numeric(new_data[,outcome_column])
bad <- is.na(required_columns)
desired_data <- new_data[!bad, ]
#find the hospitals in the rows with the minimum outcome value
columns_considered <- as.numeric(desired_data[, outcome_column])
desired_rows <- which(columns_considered == min(columns_considered))
desired_hospitals <- desired_data[desired_rows, 2]
#if there are multiple hospitals with the minimum outcome value, then
#return the first hospital name from the alphabetically sorted hospital
#names list
if (length(desired_hospitals) > 1) {
hospitals_sorted <- sort(desired_hospitals)
hospitals_sorted[1]
}
else {
desired_hospitals
}
}
# tests
best("TX", "heart attack")
#best("TX", "heart attack")
#best("TX", "heart failure")
#best("MD", "heart attack")
#best("MD", "pneumonia")
#best("BB", "heart attack")
install.packages("xlsx")
install.packages("XML")
install.packages("base64")
library(help = "base")
library(base)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality)
install.packages("ggplot2")
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality)
library(ggplot2)
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
install.packages("lattice")
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
str(nlme)
head(nlme)
tail(nlme)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies) + geom_smooth()
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
file.dest <- 'ACS.csv'
# download from the URL
download.file(file.url, file.dest, method='curl' )
# read the data
ACS <- read.csv('ACS.csv')
# create vector
ACS$agricultureLogical <- ifelse(ACS$ACR==3 & ACS$AGS==6,TRUE,FALSE)
# read lines
which(ACS$agricultureLogical)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
file.dest <- 'jeff.jpg'
# download from the URL
download.file(file.url, file.dest, mode='wb' )
# load package
library(jpeg)
# load the data
picture <- readJPEG('jeff.jpg', native=TRUE)
# get the quantile info
quantile(picture, probs = c(0.3, 0.8) )
install.packages("jpeg")
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
file.dest <- 'jeff.jpg'
# download from the URL
download.file(file.url, file.dest, mode='wb' )
# load package
library(jpeg)
# load the data
picture <- readJPEG('jeff.jpg', native=TRUE)
# get the quantile info
quantile(picture, probs = c(0.3, 0.8) )
library(jpeg)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
file.dest <- 'jeff.jpg'
# download from the URL
download.file(file.url, file.dest, mode='wb' )
# load package
library(jpeg)
# load the data
picture <- readJPEG('jeff.jpg', native=TRUE)
# get the quantile info
quantile(picture, probs = c(0.3, 0.8) )
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(file.url, file.dest, mode='wb' )
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileUrl, destfile = "jeff.jpg", method = "curl")
img.n<-readJPEG("jeff.jpg",TRUE)
quantile(img.n,probs=c(0.3,0.8))
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "gdp.csv", method = "curl")
gdp <- read.csv("./gdp.csv")
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1, destfile = "edu.csv", method = "curl")
edu <- read.csv("./edu.csv")
X=CountryCode
names(gdp)
names(edu)
head(gdp)
head(edu)
gdpclean<-gdp[5:194,]
mergedData=as.data.frame(merge(gdpclean,edu,by.x="X",by.y="CountryCode"))
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
summary(mergedData[mergedData$Income.Group=="High income: OECD",])
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
# download from the URL
download.file(file.url, file.dest )
# specify the right lines
rowNames <- seq(10,200, 2)
# read the data
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
# second data file
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
# download from the URL
download.file(file.url, file.dest )
# read second file
fed <- read.csv('GDP2.csv')
View(fed)
# merge datasets
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
# Q3.
# sort the data
combined[with(combined, order(-V2) )]
# Q4.
# OECD
mean(combined[combined$Income.Group=='High income: OECD',]$V2)
# non OECD
mean(combined[combined$Income.Group=='High income: nonOECD',]$V2)
# Q5.
# assign quentile values
quentile <- c(0.2,0.4,0.6,0.8,1)
q <- quantile(combined$V2, quentile)
q1 <- combined$V2 <= 38
xtabs(q1 ~ combined$Income.Group)
quantile(mergedData$Gross.domestic.product.2012,probs=c(0.2,0.4,0.6,0.8,1))
library(Hmisc)
mergedData$gdp=cut2(mergedData$Gross.domestic.product.2012,g=5)
table(mergedData$Income.Group,mergedData$gdp)
install.packages("Hmisc")
library("Hmisc", lib.loc="/usr/lib/rstudio/R/library")
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
# download from the URL
download.file(file.url, file.dest )
# specify the right lines
rowNames <- seq(10,200, 2)
# read the data
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
# second data file
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
# download from the URL
download.file(file.url, file.dest )
# read second file
fed <- read.csv('GDP2.csv')
View(fed)
# merge datasets
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
# Q3.
# sort the data
combined[with(combined, order(-V2) )]
# Q4.
# OECD
mean(combined[combined$Income.Group=='High income: OECD',]$V2)
# non OECD
mean(combined[combined$Income.Group=='High income: nonOECD',]$V2)
# Q5.
# assign quentile values
quentile <- c(0.2,0.4,0.6,0.8,1)
q <- quantile(combined$V2, quentile)
q1 <- combined$V2 <= 38
xtabs(q1 ~ combined$Income.Group)
# Getting and Cleaning Data
# Coursera
# John Hopkins University
# Bastiaan Quast
# bquast@gmail.com
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
# download from the URL
download.file(file.url, file.dest )
# specify the right lines
rowNames <- seq(10,200, 2)
# read the data
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
# second data file
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
# download from the URL
download.file(file.url, file.dest )
# read second file
fed <- read.csv('GDP2.csv')
View(fed)
# merge datasets
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
# Q3.
# sort the data
combined[with(combined, order(-V2) )]
# Getting and Cleaning Data
# Coursera
# John Hopkins University
# Bastiaan Quast
# bquast@gmail.com
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
# download from the URL
download.file(file.url, file.dest, method = "curl" )
# specify the right lines
rowNames <- seq(10,200, 2)
# read the data
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
# second data file
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
# download from the URL
download.file(file.url, file.dest, method = "curl" )
# read second file
fed <- read.csv('GDP2.csv')
View(fed)
# merge datasets
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
# Q3.
# sort the data
combined[with(combined, order(-V2) )]
combined[with(combined, order(V2) )]
combine[with(combined, order(-V2) )]
mean(combined[combined$Income.Group=='High income: OECD',]$V2)
# non OECD
mean(combined[combined$Income.Group=='High income: nonOECD',]$V2)
quentile <- c(0.2,0.4,0.6,0.8,1)
q <- quantile(combined$V2, quentile)
q1 <- combined$V2 <= 38
xtabs(q1 ~ combined$Income.Group)
library("plyr", lib.loc="/usr/lib/rstudio/R/library")
combine[with(combined, order(-V2) )]
combined[with(combined, order(-V2) )]
# Getting and Cleaning Data
# Coursera
# John Hopkins University
# Bastiaan Quast
# bquast@gmail.com
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
# download from the URL
download.file(file.url, file.dest, method = "curl" )
# specify the right lines
rowNames <- seq(10,200, 2)
# read the data
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
# second data file
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
# download from the URL
download.file(file.url, file.dest, method = "curl" )
# read second file
fed <- read.csv('GDP2.csv')
View(fed)
# merge datasets
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
# Q3.
# sort the data
combined[with(combined, order(-V2) )]
choose(5, 4) * 0.5^4
choose(5, 4) * 0.5^4 +  choose(5, 5) * 0.5^5
pbinom(3, size = 5, prob = 0.5, lower.tail = FALSE)
mean(rnorm(1e+03, mean = 0.5, sd = sqrt(1/12))) # 0.4999649
source('~/.active-rstudio-document')
knit2html("PA1_template.Rmd")
library("knitr", lib.loc="/usr/lib/rstudio/R/library")
knit2html("PA1_template.Rmd")
setwd("/home/ag/Data_Science_Courses/Reproducible_Research/Assignment_1/RepData_PeerAssessment1")
knit2html("PA1_template.Rmd")
